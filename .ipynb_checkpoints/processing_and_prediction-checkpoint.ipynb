{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the training, test and store data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(\"Loading the training, test and store data\")\n",
    "types = {'CompetitionOpenSinceYear': np.dtype(int),'CompetitionOpenSinceMonth': np.dtype(int),'StateHoliday': np.dtype(str),'Promo2SinceWeek': np.dtype(int),'SchoolHoliday': np.dtype(float),'PromoInterval': np.dtype(str)}\n",
    "train = pd.read_csv(\"inputs/train.csv\", parse_dates=[2], dtype=types)\n",
    "test = pd.read_csv(\"inputs/test.csv\", parse_dates=[2], dtype=types)\n",
    "store = pd.read_csv(\"inputs/store.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points considered outliers-\n",
      "Number of outliers in sales = 15863\n",
      "Number of outliers in customers = 22600\n",
      "Number of common outliers = 11334\n",
      "Dropping common outliers...\n",
      "1.90838602133 %  of data dropped\n"
     ]
    }
   ],
   "source": [
    "Q1 = np.percentile(train['Sales'], 25)\n",
    "Q3 = np.percentile(train['Sales'], 75)\n",
    "step = step = 1.5 * (Q3 - Q1)\n",
    "print \"Data points considered outliers-\"\n",
    "#display(train[~((train['Sales'] >= Q1 - step) & (train['Sales'] <= Q3 + step))])\n",
    "i=train[~((train['Sales'] >= Q1 - step) & (train['Sales'] <= Q3 + step))].index\n",
    "print \"Number of outliers in sales =\", len(i)\n",
    "Q1 = np.percentile(train['Customers'], 25)\n",
    "Q3 = np.percentile(train['Customers'], 75)\n",
    "step = step = 1.5 * (Q3 - Q1)\n",
    "#display(train[~((train['Customers'] >= Q1 - step) & (train['Customers'] <= Q3 + step))])\n",
    "j=train[~((train['Customers'] >= Q1 - step) & (train['Customers'] <= Q3 + step))].index\n",
    "print \"Number of outliers in customers =\", len(j)\n",
    "common_outliers = set(i).intersection(j)\n",
    "print \"Number of common outliers =\", len(common_outliers)\n",
    "print \"Dropping common outliers...\"\n",
    "train = train.drop(train.index[list(common_outliers)]).reset_index(drop = True)\n",
    "print float(len(common_outliers))*100/float(train.shape[0]), \"%  of data dropped\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(features, data):\n",
    "    # remove NaNs-\n",
    "    data.fillna(0, inplace=True)\n",
    "    #take the store as open if no value given-\n",
    "    data.loc[data.Open.isnull(), 'Open'] = 1\n",
    "    #only process stores which are open, otherwise whats the point:\n",
    "    data = data[data[\"Open\"] != 0]         \n",
    "    # Use some properties directly\n",
    "    features.extend(['Store', 'CompetitionDistance', 'Promo', 'Promo2', 'SchoolHoliday'])\n",
    "    # Label encode some features\n",
    "    features.extend(['StoreType', 'Assortment', 'StateHoliday'])\n",
    "    mappings = {'0':0, 'a':1, 'b':2, 'c':3, 'd':4}\n",
    "    data.StoreType.replace(mappings, inplace=True)\n",
    "    data.Assortment.replace(mappings, inplace=True)\n",
    "    data.StateHoliday.replace(mappings, inplace=True)\n",
    "\n",
    "    features.extend(['DayOfWeek', 'Month', 'Day', 'Year', 'WeekOfYear'])\n",
    "    data['Year'] = data.Date.dt.year\n",
    "    data['Month'] = data.Date.dt.month\n",
    "    data['Day'] = data.Date.dt.day\n",
    "    data['DayOfWeek'] = data.Date.dt.dayofweek\n",
    "    data['WeekOfYear'] = data.Date.dt.weekofyear\n",
    "  \n",
    "\n",
    "    # Calculate time competition open time in months\n",
    "    features.append('CompetitionOpen')\n",
    "    data['CompetitionOpen'] = 12 * (data.Year - data.CompetitionOpenSinceYear) + (data.Month - data.CompetitionOpenSinceMonth)\n",
    "    # Promo open time in months\n",
    "    features.append('PromoOpen')\n",
    "    data['PromoOpen'] = 12 * (data.Year - data.Promo2SinceYear) + (data.WeekOfYear - data.Promo2SinceWeek) / 4.0\n",
    "    data['PromoOpen'] = data.PromoOpen.apply(lambda x: x if x > 0 else 0)\n",
    "    data.loc[data.Promo2SinceYear == 0, 'PromoOpen'] = 0\n",
    "\n",
    "    # Indicate that sales on that day are in promo interval\n",
    "    features.append('IsPromoMonth')\n",
    "    month2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', 7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "    data['monthStr'] = data.Month.map(month2str)\n",
    "    data.loc[data.PromoInterval == 0, 'PromoInterval'] = ''\n",
    "    data['IsPromoMonth'] = 0\n",
    "    for interval in data.PromoInterval.unique():\n",
    "        if interval != '':\n",
    "            for month in interval.split(','):\n",
    "                data.loc[(data.monthStr == month) & (data.PromoInterval == interval), 'IsPromoMonth'] = 1\n",
    "    return features, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action = \"ignore\")\n",
    "train = pd.merge(train, store, on='Store')\n",
    "test = pd.merge(test, store, on='Store')\n",
    "features = []\n",
    "features, train= preprocess(features, train)\n",
    "\n",
    "#Drop rows where sales are zero\n",
    "train = train[train[\"Sales\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 392592 samples.\n",
      "Testing set has 98149 samples.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "# TODO: Shuffle and split the dataset into the number of training and testing points above\n",
    "X_train, X_test = cross_validation.train_test_split(train, test_size=0.2)\n",
    "\n",
    "# Show the results of the split\n",
    "print \"Training set has {} samples.\".format(X_train.shape[0])\n",
    "print \"Testing set has {} samples.\".format(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from time import time\n",
    "def train_regressor(rgr, X_train, y_train):\n",
    "    ''' Fits a regressor to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the regressor, then stop the clock\n",
    "    start = time()\n",
    "    rgr.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print \"Trained model in {:.4f} seconds\".format(end - start)\n",
    "\n",
    "    \n",
    "def predict_labels(rgr, features, target):\n",
    "    ''' Makes predictions using a fit regressor based on mean_squared_error '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = rgr.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Print and return results\n",
    "    print \"Made predictions in {:.4f} seconds.\".format(end - start)\n",
    "    #return mean_squared_error(target.values, y_pred)\n",
    "    return np.sqrt(((y_pred - target.values) ** 2).mean())\n",
    "\n",
    "\n",
    "\n",
    "def train_predict(rgr, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a regressor based on F1 score. '''\n",
    "    \n",
    "    # Indicate the regressor and the training set size\n",
    "    print \"Training a {} using a training set size of {}. . .\".format(rgr.__class__.__name__, len(X_train))\n",
    "    \n",
    "    # Train the regressor\n",
    "    train_regressor(rgr, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    print \"mean_squared_error for training set: {:.4f}.\".format(predict_labels(rgr, X_train, y_train))\n",
    "    print \"mean_squared_error for test set: {:.4f}.\".format(predict_labels(rgr, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "rgr_A = DecisionTreeRegressor(random_state=0)\n",
    "rgr_B = KNeighborsRegressor()\n",
    "rgr_C = GradientBoostingRegressor()\n",
    "i=np.log1p(X_train.Sales)\n",
    "j=np.log1p(X_test.Sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a DecisionTreeRegressor using a training set size of 392592. . .\n",
      "Trained model in 5.8305 seconds\n",
      "Made predictions in 0.5317 seconds.\n",
      "mean_squared_error for training set: 0.0000.\n",
      "Made predictions in 0.1229 seconds.\n",
      "mean_squared_error for test set: 0.1812.\n"
     ]
    }
   ],
   "source": [
    "train_predict(rgr_A, X_train[features], i, X_test[features], j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a KNeighborsRegressor using a training set size of 392592. . .\n",
      "Trained model in 2.7518 seconds\n",
      "Made predictions in 23.7530 seconds.\n",
      "mean_squared_error for training set: 0.1930.\n",
      "Made predictions in 5.8762 seconds.\n",
      "mean_squared_error for test set: 0.2444.\n"
     ]
    }
   ],
   "source": [
    "train_predict(rgr_B, X_train[features], i, X_test[features], j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a GradientBoostingRegressor using a training set size of 392592. . .\n",
      "Trained model in 72.1552 seconds\n",
      "Made predictions in 1.0902 seconds.\n",
      "mean_squared_error for training set: 0.3143.\n",
      "Made predictions in 0.2475 seconds.\n",
      "mean_squared_error for test set: 0.3154.\n"
     ]
    }
   ],
   "source": [
    "train_predict(rgr_C, X_train[features], i, X_test[features], j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 1 :DayOfWeek (0.242784)\n",
      "2. feature 0 :Store (0.207635)\n",
      "3. feature 2 :Date (0.172682)\n",
      "4. feature 13 :CompetitionOpenSinceYear (0.097464)\n",
      "5. feature 8 :SchoolHoliday (0.071592)\n",
      "6. feature 10 :Assortment (0.042990)\n",
      "7. feature 5 :Open (0.036529)\n",
      "8. feature 12 :CompetitionOpenSinceMonth (0.034023)\n",
      "9. feature 14 :Promo2 (0.033737)\n",
      "10. feature 6 :Promo (0.022285)\n",
      "11. feature 3 :Sales (0.012412)\n",
      "12. feature 9 :StoreType (0.011741)\n",
      "13. feature 11 :CompetitionDistance (0.006378)\n",
      "14. feature 4 :Customers (0.004225)\n",
      "15. feature 15 :Promo2SinceWeek (0.002041)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFOhJREFUeJzt3X+QXWd93/H3R1YMsR2TAEaL7UhK+OEUp4TQVFHrUNZ1\nC7ITKmc6TWUoJk6hzjQGN6SJgUwiOTNJw3SgIeMSqsR4+OFGGZu49pRfIoWd4qbGMjG/askWGMuS\nZcsIG/8CEln+9o9zJK6XlfautHevtM/7NXNn7znnec7znLs7n/vc55yzN1WFJKkNS8bdAUnSwjH0\nJakhhr4kNcTQl6SGGPqS1BBDX5IaYuirOUn+JMlvj7sf0jjE6/Q1rCT3AM8DngQCFPDiqnrgKPb5\nSuDDVfWj89LJ40ySa4CdVfW74+6L2rB03B3QcaWAn6+qz8zjPg+8eRxZ5eSEqto/j/1ZMEn8pK0F\n5x+d5iozrkxWJ/k/SR5Ocns/gj+w7ZeT3JHk0SRfTfLv+vUnAR8DTk/yWL99Isk1SX5voP4rk+wc\nWP56kt9K8kXg8SRLkjw/yfVJHkzytSRvPuQBDOz/wL6T/GaSPUnuS7I2yflJ7kyyN8nbB+quT3Jd\nkk19f29L8tKB7T+R5DP96/DlJK+Z1u57k3w0yWPAvwVeB/xWv68b+3JX9K/To0m+kuTCgX28Icln\nk/znJA/1x7pmYPuPJHl/fxzfTPKXA9t+of/dPJzk5iR/f2DbFUl29W1uTXLuoV4/HeeqyoePoR7A\n14F/OsP604G9wKv75fP65ef0y+cDK/vnrwCeAF7WL78SuHfa/q4Bfm9g+Wll+n78Td/uM+jeiG4D\nfhs4AVgJfBX454c4joP77/e9b6DuG4EHgQ8DJwEvAb4NrOjLrwf+FvjFvvxvAHf3z5cC24Er+ufn\nAo8CLxpo92Fgdb/8jOnH2q//l8Cy/vm/Ah4fWH5D3/6v9Mf9q8B9A3U/Cvw5cGrfp1f0638a2AP8\nTF/v9f3r+APAi4F7B9pYDvzYuP/efIzm4Uhfc/U/+hHmQwOjyH8DfLSqPglQVf+LLoQv6Jc/XlX3\n9M8/C2ymC/+j8Z6q2l1Vfwv8Q+C5VfX7VbW/b+vPgHVD7uvvgD+obppoE/Bc4I+q6ttVdQdwB/BT\nA+U/X1U39OXfTRfeq/vHyVX1zqp6srppsP8JXDRQ98aqugWg7/v3qaqPVNWe/vl1dG8kqwaK7Kiq\n91dVAR8Anp/keUkmgFcDl1bVo/1r8dm+zpuA91XVbdX5EN2bx2pgP3Ai8JNJllbVvVX19SFfOx1n\nnNPXXK2t75/TXwH80sBURuj+tj4NkOR84HfpRpRLgB8EvnSU/dg1rf0zkjw00P4S4H8Pua9v9gEK\n8J3+54MD278DnDKwfHCqqaoqyX10nzoyuK23AzhjprqHkuRi4NfpPrEAnEz3RnTAwRPnVfWdJPT9\new7wUFU9OsNuVwAXD0x7hW6Uf3pVfTbJfwA2AC9J8kngN6rq/tn6quOPoa+5mmlOfyfwwaq69PsK\nJycC19N9Grixqp5KcsPAfmY6ifsE3dTKAc+focxgvZ3A3VV11hD9nw8HrzRKl7hnArvpjmn5tLLL\ngTsHlqcf79OWkywHNgLnVtX/7dfdziHOpUyzE3h2klNnCP6dwO9X1X+aqWJVbQI2JTmlb/8P6aaS\ntMg4vaP58GHgNUle1Z9UfWZ/gvR0ummDE4G9feCfD7xqoO4e4DlJTh1Y9wXggv6k5ARw+Szt3wo8\n1p/cfWaSE5KcneRn5u8Qn+YfJLkwyQl0I/LvArcAnwOe6PuxNMkk8At0c+yHsgf48YHlk4GngL39\na3kJ8JPDdKq6S2c/Drw3yQ/3fTgwjfanwK8mWQWQ5OQkF/Q/X5zk3P4N+u/oPtk8NdQroeOOoa+5\nmPHSyqraBawF3gF8g25K4z8CS6rqceAtwHX99Ms64MaBunfSheLd/XmCCeBDdNM/9wCfoJtnP2Q/\nquopunB9Gd3JyQfpQu5UjsxhR+N9//813UnZ1wG/2M+f7wNeQ3cuYy9wFfD6qtp+iP0AXA2cfeAc\nSVVtpTtPcAvdNM7ZwM1z6O/r6e6j2Eb3hnI5QFV9nm5e/6r+93AX3xvJP4NuZP8Nuk8spwFvR4vS\nUDdn9ZeE/RHdm8TVVfXOadtfS3fFAsBjwL+vqi/12+4BHqEbOeyrqsETUtJxJcl64AVVdfG4+yId\niVnn9NPdQHIV3WV4u4EtSW6sqm0Dxe4G/klVPdK/QWykuyoAurCfrKqH57frkqS5GmZ6ZxWwvap2\n9B9fN9F9lD+oqm6pqkf6xVt4+tUKB66kkCSN2TBX75zB0y8z28XTrxme7o10J5MOKOBTSfYDG6vq\nT+fcS+kYUVVXjrsP0tGY10s2+1u3LwF+bmD1OVV1f5LT6MJ/a1XNdmJKkjQCw4T+fTz92uMz+3VP\n0///kY3AmsH5+wM3eFTVN/rrs1cxw9UISfx3n5I0R1U1zD0cBw0z174FeGGSFf11vOuAmwYL9DeU\nfITu8rSvDaw/qb/ZgyQn012f/ZXDdH7BH+vXrx/7/8LwmD1mj9ljPpLHkZh1pF9V+5NcRvf/Ug5c\nsrk1yaXd5toI/A7wbLqbQsL3Ls1cBtzQj+KXAtdW1eYj6qkk6agNNadfVZ8Azpq27r8NPH8T3Y0f\n0+t9ne6GGUnSMaD5SyknJyfH3YUF5zG3wWPWTI6Zr0tMUsdKXyTpeJCEGsGJXEnSImHoS1JDDH1J\naoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SG\nGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1Jaoih\nL0kNMfQlqSGGviQ1xNCXpIYY+mMyMbGSJCN9TEysHPdhSjrGpKrG3QcAktSx0peFkAQY9fGGll5T\nqTVJqKrMpY4jfUlqyFChn2RNkm1J7kpyxQzbX5vki/3j5iQvHbauJGnhzDq9k2QJcBdwHrAb2AKs\nq6ptA2VWA1ur6pEka4ANVbV6mLoD+3B6Z/5bcXpHWsRGNb2zCtheVTuqah+wCVg7WKCqbqmqR/rF\nW4Azhq0rSVo4w4T+GcDOgeVdfC/UZ/JG4ONHWFeSNEJL53NnSc4FLgF+7kjqb9iw4eDzyclJJicn\n56VfkrQYTE1NMTU1dVT7GGZOfzXdHP2afvltQFXVO6eVeynwEWBNVX1tLnX7bc7pz38rzulLi9io\n5vS3AC9MsiLJicA64KZpDS+nC/zXHwj8YetKkhbOrNM7VbU/yWXAZro3iauramuSS7vNtRH4HeDZ\nwHvTDWH3VdWqQ9Ud2dFIkg7LO3LHxOkdSUfLO3IlSYdl6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQ\nl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1J\naoihL0kNMfQbNDGxkiQje0xMrBz3IUo6hFTVuPsAQJI6VvqyEJIAoz7eMNNrOvq2Z25X0vxKQlVl\nLnUc6UtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWp\nIYa+JDVkqNBPsibJtiR3Jblihu1nJfnrJN9N8tZp2+5J8sUktye5db46Lkmau6WzFUiyBLgKOA/Y\nDWxJcmNVbRso9k3gzcCFM+ziKWCyqh6eh/5Kko7CMCP9VcD2qtpRVfuATcDawQJVtbeqPg88OUP9\nDNmOJGnEhgnjM4CdA8u7+nXDKuBTSbYkedNcOidJml+zTu/Mg3Oq6v4kp9GF/9aqunkB2pUkTTNM\n6N8HLB9YPrNfN5Squr//+Y0kN9BNF80Y+hs2bDj4fHJyksnJyWGbkaRFb2pqiqmpqaPax6zfkZvk\nBOBOuhO59wO3AhdV1dYZyq4HHq+qd/XLJwFLqurxJCcDm4Erq2rzDHX9jtz5b8XvyJUWsSP5jtxZ\nR/pVtT/JZXSBvQS4uqq2Jrm021wbkywDbgN+CHgqyeXAS4DTgBuSVN/WtTMFviRpYcw60l8ojvRH\n0oojfWkRO5KRvpdSSlJDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqI\noS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6\nktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9J\nDTH0JakhQ4V+kjVJtiW5K8kVM2w/K8lfJ/lukrfOpa4kaeGkqg5fIFkC3AWcB+wGtgDrqmrbQJnn\nAiuAC4GHq+rdw9Yd2EfN1pfFJAkw6uMNM72mo2975nYlza8kVFXmUmeYkf4qYHtV7aiqfcAmYO1g\ngaraW1WfB56ca11J0sIZJvTPAHYOLO/q1w3jaOpKkuaZJ3IlqSFLhyhzH7B8YPnMft0w5lR3w4YN\nB59PTk4yOTk5ZDOStPhNTU0xNTV1VPsY5kTuCcCddCdj7wduBS6qqq0zlF0PPF5V7zqCup7Inf9W\nPJErLWJHciJ31pF+Ve1PchmwmW466Oqq2prk0m5zbUyyDLgN+CHgqSSXAy+pqsdnqjvH49IiMTGx\nkj17doy0jWXLVvDAA/eMtA3peDbrSH+hONIfSSvH1Eh/nMcsLUajumRTkrRIGPqS1BBDX5IaYuhL\nUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1\nxNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoa8mTEysJMnIHhMTK8d9iNJQUlXj7gMASepY6ctCSAKM\n+njDTK/p6NseV7vjbHvmdqVRSkJVZS51HOlLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQ\nQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1ZKjQT7ImybYkdyW54hBl/jjJ9iRfSPLTA+vvSfLF\nJLcnuXW+Oi5JmrulsxVIsgS4CjgP2A1sSXJjVW0bKHM+8IKqelGSnwX+BFjdb34KmKyqh+e995Kk\nORlmpL8K2F5VO6pqH7AJWDutzFrggwBV9TngWUmW9dsyZDuSpBEbJozPAHYOLO/q1x2uzH0DZQr4\nVJItSd50pB2VJB29Wad35sE5VXV/ktPown9rVd08U8ENGzYcfD45Ocnk5OQCdE+Sjg9TU1NMTU0d\n1T5m/brEJKuBDVW1pl9+G1BV9c6BMu8DPlNVf9EvbwNeWVV7pu1rPfBYVb17hnb8usT5b+WY+urA\nFo9ZGqVRfV3iFuCFSVYkORFYB9w0rcxNwMV9J1YD36qqPUlOSnJKv/5k4FXAV+bSQUnS/Jl1eqeq\n9ie5DNhM9yZxdVVtTXJpt7k2VtXHklyQ5KvAE8AlffVlwA1Jqm/r2qraPJpDkSTNZtbpnYXi9M5I\nWjmmpjpaPGZplEY1vSNJWiQMfWmEJiZWkmSkj4mJleM+TB1HnN4ZkxanOjzmhW1bi5/TO5KkwzL0\nJakhhr4kNcTQl6SGGPrSIjXqK4e8auj45NU7Y+KVLIutbY9ZC8+rdySNnZ8wjm2O9MekxRGgx7zY\n2j622oXuDWfPnh0ja3nZshU88MA9I9v/XB3JSN/QHxPDYLG17TGPu91xtz0OTu9Ikg7L0Jekhhj6\nktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQdpePpX094R+6YeKfmYmvbYx53u+Nse5ztekeu\nJOmQDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4k\nNWSo0E+yJsm2JHclueIQZf44yfYkX0jysrnUlSQtjFlDP8kS4Crg1cDZwEVJfmJamfOBF1TVi4BL\ngfcNW3fcpqamxt0FSVoww4z0VwHbq2pHVe0DNgFrp5VZC3wQoKo+BzwrybIh646VoS+pJcOE/hnA\nzoHlXf26YcoMU1eStEBGdSJ3Tt/kIklaGEuHKHMfsHxg+cx+3fQyPzpDmROHqHtQ95VjC+/KK68c\nS7sL8d546Nd0tG2Pq91xtu0xHwvtjrPtcR7z8IYJ/S3AC5OsAO4H1gEXTStzE/BrwF8kWQ18q6r2\nJNk7RF2AOX/PoyRp7mYN/aran+QyYDPddNDVVbU1yaXd5tpYVR9LckGSrwJPAJccru7IjkaSdFg5\n1LfKS5IWn2bvyG3tprEkZyb5dJL/l+TLSd4y7j4tlCRLkvxNkpvG3ZeFkORZSa5LsrX/ff/suPs0\nakl+PclXknwpybVJThx3n+ZbkquT7EnypYF1P5Jkc5I7k3wyybNm20+ToX883DQ2Ak8Cb62qs4F/\nBPxaA8d8wOXAHePuxAJ6D/Cxqvp7wE8Bi3pKNcnpwJuBl1fVS+mmrdeNt1cjcQ1dZg16G/BXVXUW\n8Gng7bPtpMnQ5zi4aWy+VdUDVfWF/vnjdEGw6O+ZSHImcAHwZ+Puy0JIcirwiqq6BqCqnqyqR8fc\nrYVwAnBykqXAScDuMfdn3lXVzcDD01avBT7QP/8AcOFs+2k19Ju+aSzJSuBlwOfG25MF8V+A3wRa\nOXn1Y8DeJNf0U1obk/zguDs1SlW1G3gXcC/dJeHfqqq/Gm+vFszzqmoPdAM74HmzVWg19JuV5BTg\neuDyfsS/aCX5eWBP/wkntHHT4FLg5cB/raqXA9+mmwJYtJL8MN2IdwVwOnBKkteOt1djM+vgptXQ\nH+aGs0Wn/+h7PfChqrpx3P1ZAOcA/yLJ3cCfA+cm+eCY+zRqu4CdVXVbv3w93ZvAYvbPgLur6qGq\n2g/8JfCPx9ynhbKn/z9nJJkAHpytQquhf/CGs/4s/zq6G8wWu/cDd1TVe8bdkYVQVe+oquVV9eN0\nv+NPV9XF4+7XKPUf9XcmeXG/6jwW/0nse4HVSZ6Z7rbV81i8J6+nf2K9Cfjl/vkbgFkHc8Pckbvo\ntHjTWJJzgNcBX05yO93HwHdU1SfG2zONwFuAa5P8AHA3/c2Si1VV3ZrkeuB2YF//c+N4ezX/kvx3\nYBJ4TpJ7gfXAHwLXJfkVYAfwS7Pux5uzJKkdrU7vSFKTDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY\n+pLUEENfkhry/wHdBsbdJg8SKAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f44731bf8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "importances = rgr_A.feature_importances_ \n",
    "# return the indices that would sort the importance, decreasing\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(15):\n",
    "    print(\"%d. feature %d :%s (%f)\" % (f + 1, indices[f],X_train.columns[indices[f]], importances[indices[f]]))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(1,10), importances[indices[range(1,10)]]) \n",
    "plt.xlim([-1, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train over complete dataset and predict test-\n",
    "p=[]\n",
    "p, test= preprocess(p, test)\n",
    "i=np.log1p(train.Sales)\n",
    "rgr_A.fit(train[features], i)\n",
    "pred =rgr_A.predict(test[features])\n",
    "p_Sales =rgr_A.predict(test[features])\n",
    "test['p_Sales'] = np.expm1(p_Sales)\n",
    "test.to_csv(\"prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
