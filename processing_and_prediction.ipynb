{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the training, test and store data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(\"Loading the training, test and store data\")\n",
    "types = {'CompetitionOpenSinceYear': np.dtype(int),'CompetitionOpenSinceMonth': np.dtype(int),'StateHoliday': np.dtype(str),'Promo2SinceWeek': np.dtype(int),'SchoolHoliday': np.dtype(float),'PromoInterval': np.dtype(str)}\n",
    "train = pd.read_csv(\"inputs/train.csv\", parse_dates=[2], dtype=types)\n",
    "test = pd.read_csv(\"inputs/test.csv\", parse_dates=[2], dtype=types)\n",
    "store = pd.read_csv(\"inputs/store.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points considered outliers-\n",
      "Number of outliers in sales = 15863\n",
      "Number of outliers in customers = 22600\n",
      "Number of common outliers = 11334\n",
      "Dropping common outliers...\n",
      "1.90838602133 %  of data dropped\n"
     ]
    }
   ],
   "source": [
    "Q1 = np.percentile(train['Sales'], 25)\n",
    "Q3 = np.percentile(train['Sales'], 75)\n",
    "step = step = 1.5 * (Q3 - Q1)\n",
    "print \"Data points considered outliers-\"\n",
    "#display(train[~((train['Sales'] >= Q1 - step) & (train['Sales'] <= Q3 + step))])\n",
    "i=train[~((train['Sales'] >= Q1 - step) & (train['Sales'] <= Q3 + step))].index\n",
    "print \"Number of outliers in sales =\", len(i)\n",
    "Q1 = np.percentile(train['Customers'], 25)\n",
    "Q3 = np.percentile(train['Customers'], 75)\n",
    "step = step = 1.5 * (Q3 - Q1)\n",
    "#display(train[~((train['Customers'] >= Q1 - step) & (train['Customers'] <= Q3 + step))])\n",
    "j=train[~((train['Customers'] >= Q1 - step) & (train['Customers'] <= Q3 + step))].index\n",
    "print \"Number of outliers in customers =\", len(j)\n",
    "common_outliers = set(i).intersection(j)\n",
    "print \"Number of common outliers =\", len(common_outliers)\n",
    "print \"Dropping common outliers...\"\n",
    "train = train.drop(train.index[list(common_outliers)]).reset_index(drop = True)\n",
    "print float(len(common_outliers))*100/float(train.shape[0]), \"%  of data dropped\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(features, data):\n",
    "    # remove NaNs-\n",
    "    data.fillna(0, inplace=True)\n",
    "    #take the store as open if no value given-\n",
    "    data.loc[data.Open.isnull(), 'Open'] = 1\n",
    "    #only process stores which are open, otherwise whats the point:\n",
    "    data = data[data[\"Open\"] != 0]         \n",
    "    # Use some properties directly\n",
    "    features.extend(['Store', 'CompetitionDistance', 'Promo', 'Promo2', 'SchoolHoliday'])\n",
    "    # Label encode some features\n",
    "    features.extend(['StoreType', 'Assortment', 'StateHoliday'])\n",
    "    mappings = {'0':0, 'a':1, 'b':2, 'c':3, 'd':4}\n",
    "    data.StoreType.replace(mappings, inplace=True)\n",
    "    data.Assortment.replace(mappings, inplace=True)\n",
    "    data.StateHoliday.replace(mappings, inplace=True)\n",
    "\n",
    "    features.extend(['DayOfWeek', 'Month', 'Day', 'Year', 'WeekOfYear'])\n",
    "    data['Year'] = data.Date.dt.year\n",
    "    data['Month'] = data.Date.dt.month\n",
    "    data['Day'] = data.Date.dt.day\n",
    "    data['DayOfWeek'] = data.Date.dt.dayofweek\n",
    "    data['WeekOfYear'] = data.Date.dt.weekofyear\n",
    "  \n",
    "\n",
    "    # Calculate time competition open time in months\n",
    "    features.append('CompetitionOpen')\n",
    "    data['CompetitionOpen'] = 12 * (data.Year - data.CompetitionOpenSinceYear) + (data.Month - data.CompetitionOpenSinceMonth)\n",
    "    # Promo open time in months\n",
    "    features.append('PromoOpen')\n",
    "    data['PromoOpen'] = 12 * (data.Year - data.Promo2SinceYear) + (data.WeekOfYear - data.Promo2SinceWeek) / 4.0\n",
    "    data['PromoOpen'] = data.PromoOpen.apply(lambda x: x if x > 0 else 0)\n",
    "    data.loc[data.Promo2SinceYear == 0, 'PromoOpen'] = 0\n",
    "\n",
    "    # Indicate that sales on that day are in promo interval\n",
    "    features.append('IsPromoMonth')\n",
    "    month2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', 7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "    data['monthStr'] = data.Month.map(month2str)\n",
    "    data.loc[data.PromoInterval == 0, 'PromoInterval'] = ''\n",
    "    data['IsPromoMonth'] = 0\n",
    "    for interval in data.PromoInterval.unique():\n",
    "        if interval != '':\n",
    "            for month in interval.split(','):\n",
    "                data.loc[(data.monthStr == month) & (data.PromoInterval == interval), 'IsPromoMonth'] = 1\n",
    "    return features, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action = \"ignore\")\n",
    "train = pd.merge(train, store, on='Store')\n",
    "test = pd.merge(test, store, on='Store')\n",
    "features = []\n",
    "features, train= preprocess(features, train)\n",
    "\n",
    "#Drop rows where sales are zero\n",
    "train = train[train[\"Sales\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 392592 samples.\n",
      "Testing set has 98149 samples.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "# TODO: Shuffle and split the dataset into the number of training and testing points above\n",
    "X_train, X_test = cross_validation.train_test_split(train, test_size=0.2)\n",
    "\n",
    "# Show the results of the split\n",
    "print \"Training set has {} samples.\".format(X_train.shape[0])\n",
    "print \"Testing set has {} samples.\".format(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from time import time\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print \"Trained model in {:.4f} seconds\".format(end - start)\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on mean_squared_error '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Print and return results\n",
    "    print \"Made predictions in {:.4f} seconds.\".format(end - start)\n",
    "    #return mean_squared_error(target.values, y_pred)\n",
    "    return np.sqrt(((y_pred - target.values) ** 2).mean())\n",
    "\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print \"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    print \"mean_squared_error for training set: {:.4f}.\".format(predict_labels(clf, X_train, y_train))\n",
    "    print \"mean_squared_error for test set: {:.4f}.\".format(predict_labels(clf, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "clf_A = DecisionTreeRegressor(random_state=0)\n",
    "clf_B = KNeighborsRegressor()\n",
    "clf_C = GradientBoostingRegressor()\n",
    "i=np.log(X_train[\"Sales\"] + 1)\n",
    "j=np.log(X_test[\"Sales\"] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a DecisionTreeRegressor using a training set size of 392592. . .\n",
      "Trained model in 6.2317 seconds\n",
      "Made predictions in 0.5872 seconds.\n",
      "mean_squared_error for training set: 0.0000.\n",
      "Made predictions in 0.1129 seconds.\n",
      "mean_squared_error for test set: 0.1843.\n"
     ]
    }
   ],
   "source": [
    "train_predict(clf_A, X_train[features], i, X_test[features], j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a KNeighborsRegressor using a training set size of 392592. . .\n",
      "Trained model in 3.2916 seconds\n",
      "Made predictions in 24.8898 seconds.\n",
      "mean_squared_error for training set: 0.1931.\n",
      "Made predictions in 6.3581 seconds.\n",
      "mean_squared_error for test set: 0.2443.\n"
     ]
    }
   ],
   "source": [
    "train_predict(clf_B, X_train[features], i, X_test[features], j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a GradientBoostingRegressor using a training set size of 392592. . .\n",
      "Trained model in 65.0168 seconds\n",
      "Made predictions in 1.1450 seconds.\n",
      "mean_squared_error for training set: 0.3159.\n",
      "Made predictions in 0.2668 seconds.\n",
      "mean_squared_error for test set: 0.3170.\n"
     ]
    }
   ],
   "source": [
    "train_predict(clf_C, X_train[features], i, X_test[features], j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 1 :Store (0.244519)\n",
      "2. feature 0 :DayOfWeek (0.207873)\n",
      "3. feature 2 :Date (0.172411)\n",
      "4. feature 13 :Sales (0.092970)\n",
      "5. feature 8 :Customers (0.072718)\n",
      "6. feature 10 :Open (0.042956)\n",
      "7. feature 12 :Promo (0.036449)\n",
      "8. feature 14 :StateHoliday (0.035402)\n",
      "9. feature 5 :SchoolHoliday (0.035377)\n",
      "10. feature 6 :StoreType (0.020011)\n",
      "11. feature 3 :Assortment (0.013925)\n",
      "12. feature 9 :CompetitionDistance (0.010723)\n",
      "13. feature 11 :CompetitionOpenSinceMonth (0.006695)\n",
      "14. feature 4 :CompetitionOpenSinceYear (0.004364)\n",
      "15. feature 15 :Promo2 (0.002053)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJakhhr4kNeT/A69Eov1CQp34AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb4145a3150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "importances = clf_A.feature_importances_ \n",
    "# return the indices that would sort the importance, decreasing\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(15):\n",
    "    print(\"%d. feature %d :%s (%f)\" % (f + 1, indices[f],X_train.columns[f], importances[indices[f]]))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(1,10), importances[indices[range(1,10)]]) \n",
    "plt.xlim([-1, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train over complete dataset and predict test-\n",
    "p=[]\n",
    "p, test= preprocess(p, test)\n",
    "pred =clf_A.predict(test[features])\n",
    "test['p_Sales'] =clf_A.predict(test[features])\n",
    "test.to_csv(\"predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
