{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the training, test and store data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(\"Loading the training, test and store data\")\n",
    "types = {'CompetitionOpenSinceYear': np.dtype(int),'CompetitionOpenSinceMonth': np.dtype(int),'StateHoliday': np.dtype(str),'Promo2SinceWeek': np.dtype(int),'SchoolHoliday': np.dtype(float),'PromoInterval': np.dtype(str)}\n",
    "train = pd.read_csv(\"inputs/train.csv\", parse_dates=[2], dtype=types)\n",
    "test = pd.read_csv(\"inputs/test.csv\", parse_dates=[2], dtype=types)\n",
    "store = pd.read_csv(\"inputs/store.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points considered outliers-\n",
      "Number of outliers in sales = 15863\n",
      "Number of outliers in customers = 22600\n",
      "Number of common outliers = 11334\n",
      "Dropping common outliers...\n",
      "1.90838602133 %  of data dropped\n"
     ]
    }
   ],
   "source": [
    "Q1 = np.percentile(train['Sales'], 25)\n",
    "Q3 = np.percentile(train['Sales'], 75)\n",
    "step = step = 1.5 * (Q3 - Q1)\n",
    "print \"Data points considered outliers-\"\n",
    "#display(train[~((train['Sales'] >= Q1 - step) & (train['Sales'] <= Q3 + step))])\n",
    "i=train[~((train['Sales'] >= Q1 - step) & (train['Sales'] <= Q3 + step))].index\n",
    "print \"Number of outliers in sales =\", len(i)\n",
    "Q1 = np.percentile(train['Customers'], 25)\n",
    "Q3 = np.percentile(train['Customers'], 75)\n",
    "step = step = 1.5 * (Q3 - Q1)\n",
    "#display(train[~((train['Customers'] >= Q1 - step) & (train['Customers'] <= Q3 + step))])\n",
    "j=train[~((train['Customers'] >= Q1 - step) & (train['Customers'] <= Q3 + step))].index\n",
    "print \"Number of outliers in customers =\", len(j)\n",
    "common_outliers = set(i).intersection(j)\n",
    "print \"Number of common outliers =\", len(common_outliers)\n",
    "print \"Dropping common outliers...\"\n",
    "train = train.drop(train.index[list(common_outliers)]).reset_index(drop = True)\n",
    "print float(len(common_outliers))*100/float(train.shape[0]), \"%  of data dropped\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(features, data):\n",
    "    # remove NaNs-\n",
    "    data.fillna(0, inplace=True)\n",
    "    #take the store as open if no value given-\n",
    "    data.loc[data.Open.isnull(), 'Open'] = 1\n",
    "    #only process stores which are open, otherwise whats the point:\n",
    "    data = data[data[\"Open\"] != 0]         \n",
    "    # Use some properties directly\n",
    "    features.extend(['Store', 'CompetitionDistance', 'Promo', 'Promo2', 'SchoolHoliday'])\n",
    "    # Label encode some features\n",
    "    features.extend(['StoreType', 'Assortment', 'StateHoliday'])\n",
    "    mappings = {'0':0, 'a':1, 'b':2, 'c':3, 'd':4}\n",
    "    data.StoreType.replace(mappings, inplace=True)\n",
    "    data.Assortment.replace(mappings, inplace=True)\n",
    "    data.StateHoliday.replace(mappings, inplace=True)\n",
    "\n",
    "    features.extend(['DayOfWeek', 'Month', 'Day', 'Year', 'WeekOfYear'])\n",
    "    data['Year'] = data.Date.dt.year\n",
    "    data['Month'] = data.Date.dt.month\n",
    "    data['Day'] = data.Date.dt.day\n",
    "    data['DayOfWeek'] = data.Date.dt.dayofweek\n",
    "    data['WeekOfYear'] = data.Date.dt.weekofyear\n",
    "  \n",
    "\n",
    "    # Calculate time competition open time in months\n",
    "    features.append('CompetitionOpen')\n",
    "    data['CompetitionOpen'] = 12 * (data.Year - data.CompetitionOpenSinceYear) + (data.Month - data.CompetitionOpenSinceMonth)\n",
    "    # Promo open time in months\n",
    "    features.append('PromoOpen')\n",
    "    data['PromoOpen'] = 12 * (data.Year - data.Promo2SinceYear) + (data.WeekOfYear - data.Promo2SinceWeek) / 4.0\n",
    "    data['PromoOpen'] = data.PromoOpen.apply(lambda x: x if x > 0 else 0)\n",
    "    data.loc[data.Promo2SinceYear == 0, 'PromoOpen'] = 0\n",
    "\n",
    "    # Indicate that sales on that day are in promo interval\n",
    "    features.append('IsPromoMonth')\n",
    "    month2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', 7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "    data['monthStr'] = data.Month.map(month2str)\n",
    "    data.loc[data.PromoInterval == 0, 'PromoInterval'] = ''\n",
    "    data['IsPromoMonth'] = 0\n",
    "    for interval in data.PromoInterval.unique():\n",
    "        if interval != '':\n",
    "            for month in interval.split(','):\n",
    "                data.loc[(data.monthStr == month) & (data.PromoInterval == interval), 'IsPromoMonth'] = 1\n",
    "    return features, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action = \"ignore\")\n",
    "train = pd.merge(train, store, on='Store')\n",
    "test = pd.merge(test, store, on='Store')\n",
    "features = []\n",
    "features, train= preprocess(features, train)\n",
    "\n",
    "#Drop rows where sales are zero\n",
    "train = train[train[\"Sales\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 392592 samples.\n",
      "Testing set has 98149 samples.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "# TODO: Shuffle and split the dataset into the number of training and testing points above\n",
    "X_train, X_test = cross_validation.train_test_split(train, test_size=0.2)\n",
    "\n",
    "# Show the results of the split\n",
    "print \"Training set has {} samples.\".format(X_train.shape[0])\n",
    "print \"Testing set has {} samples.\".format(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from time import time\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print \"Trained model in {:.4f} seconds\".format(end - start)\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on mean_squared_error '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Print and return results\n",
    "    print \"Made predictions in {:.4f} seconds.\".format(end - start)\n",
    "    #return mean_squared_error(target.values, y_pred)\n",
    "    return np.sqrt(((y_pred - target.values) ** 2).mean())\n",
    "\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print \"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    print \"mean_squared_error for training set: {:.4f}.\".format(predict_labels(clf, X_train, y_train))\n",
    "    print \"mean_squared_error for test set: {:.4f}.\".format(predict_labels(clf, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "clf_A = DecisionTreeRegressor(random_state=0)\n",
    "clf_B = KNeighborsRegressor()\n",
    "clf_C = GradientBoostingRegressor()\n",
    "i=np.log(X_train[\"Sales\"] + 1)\n",
    "j=np.log(X_test[\"Sales\"] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a DecisionTreeRegressor using a training set size of 392592. . .\n",
      "Trained model in 6.3615 seconds\n",
      "Made predictions in 0.6946 seconds.\n",
      "mean_squared_error for training set: 0.0000.\n",
      "Made predictions in 0.1140 seconds.\n",
      "mean_squared_error for test set: 0.1819.\n"
     ]
    }
   ],
   "source": [
    "train_predict(clf_A, X_train[features], i, X_test[features], j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a KNeighborsRegressor using a training set size of 392592. . .\n",
      "Trained model in 3.6165 seconds\n",
      "Made predictions in 23.1225 seconds.\n",
      "mean_squared_error for training set: 0.1927.\n",
      "Made predictions in 5.8234 seconds.\n",
      "mean_squared_error for test set: 0.2470.\n"
     ]
    }
   ],
   "source": [
    "train_predict(clf_B, X_train[features], i, X_test[features], j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a GradientBoostingRegressor using a training set size of 392592. . .\n",
      "Trained model in 71.3005 seconds\n",
      "Made predictions in 1.1283 seconds.\n",
      "mean_squared_error for training set: 0.3151.\n",
      "Made predictions in 0.2588 seconds.\n",
      "mean_squared_error for test set: 0.3181.\n"
     ]
    }
   ],
   "source": [
    "train_predict(clf_C, X_train[features], i, X_test[features], j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 1 :Store (0.254123)\n",
      "2. feature 0 :DayOfWeek (0.200575)\n",
      "3. feature 2 :Date (0.172812)\n",
      "4. feature 13 :Sales (0.095197)\n",
      "5. feature 8 :Customers (0.074495)\n",
      "6. feature 10 :Open (0.042988)\n",
      "7. feature 12 :Promo (0.034619)\n",
      "8. feature 14 :StateHoliday (0.033541)\n",
      "9. feature 5 :SchoolHoliday (0.033104)\n",
      "10. feature 6 :StoreType (0.021846)\n",
      "11. feature 3 :Assortment (0.011782)\n",
      "12. feature 9 :CompetitionDistance (0.010593)\n",
      "13. feature 11 :CompetitionOpenSinceMonth (0.006468)\n",
      "14. feature 4 :CompetitionOpenSinceYear (0.004213)\n",
      "15. feature 15 :Promo2 (0.002126)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkhpi6EtSQwx9SWqIoS9JDTH0Jakh/x9P2ZYZCYeT5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fadfc4bfa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "importances = clf_A.feature_importances_ \n",
    "# return the indices that would sort the importance, decreasing\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(15):\n",
    "    print(\"%d. feature %d :%s (%f)\" % (f + 1, indices[f],X_train.columns[f], importances[indices[f]]))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(1,10), importances[indices[range(1,10)]]) \n",
    "plt.xlim([-1, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train over complete dataset and predict test-\n",
    "p=[]\n",
    "p, test= preprocess(p, test)\n",
    "i=np.log(train[\"Sales\"] + 1)\n",
    "clf_A.fit(train[features], i)\n",
    "pred =clf_A.predict(test[features])\n",
    "test['p_Sales'] =clf_A.predict(test[features])\n",
    "test.to_csv(\"prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
